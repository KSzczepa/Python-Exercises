{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #For array managment\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from Simulation import simulation as sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DKL(l1,l2):\n",
    "    ###Kullback-Leibler divergence between two arrays, they have to be pmfs (ie histograms that sum to 1)\n",
    "    return(np.sum([l1[i]*math.log(l1[i]/l2[i]) for i in range(len(l1)) if l1[i]!=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 3 #For each move, we have four contributors\n",
    "\n",
    "#declared by the user range(3-10) from 3x3 to 10x10\n",
    "grid_dimension = 5\n",
    "fields_number = grid_dimension*grid_dimension\n",
    "grid = []\n",
    "state_memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWall(x):\n",
    "    ###Check if the agent is near a wall on square x\n",
    "    # Returns a list of ints, one for each wall (in Python 1<=>True, 0<=>False)\n",
    "    res = [0, 0, 0, 0]\n",
    "    if x % grid_dimension == 0:  # If the agent is near the left-side wall, update the list\n",
    "        res[0] = 1\n",
    "    if x % grid_dimension == (grid_dimension - 1):  # If the agent is near the right-side wall, update the list\n",
    "        res[2] = 1\n",
    "    if x // grid_dimension == 0:  # If the agent is near the bottom-side wall, update the list\n",
    "        res[3] = 1\n",
    "    if x // grid_dimension == (grid_dimension - 1):  # If the agent is near the top-side wall, update the list\n",
    "        res[1] = 1\n",
    "\n",
    "    return (res)  # Return the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_direction():\n",
    "    # arrange the list in the correct order\n",
    "    startindex = grid_dimension\n",
    "    stopindex = 0\n",
    "    step = -1\n",
    "    field_number = 0\n",
    "    cnt = 0\n",
    "    for i in range(startindex, stopindex, step):\n",
    "        for j in range(0, grid_dimension, 1):\n",
    "            field_number = (grid_dimension * i) - grid_dimension + j\n",
    "            grid.insert(cnt, field_number)\n",
    "            cnt += 1\n",
    "\n",
    "    ## Fields for whose GO right determined on the basis of the diagonal\n",
    "    squaresGoRight = []\n",
    "    rows = grid_dimension;  # const value\n",
    "    cols = grid_dimension;\n",
    "    counter = 0;\n",
    "\n",
    "    for j in range(fields_number):\n",
    "        if (counter == rows):  # in 1st row take all, in next take 1 less\n",
    "            counter = 0\n",
    "            cols = cols - 1  # decrise\n",
    "        if (counter < cols):\n",
    "            squaresGoRight.append(grid[j])\n",
    "        counter = counter + 1\n",
    "\n",
    "    ## Fields for whose GO up, rest of the grid\n",
    "    squaresGoUp = [squareNumber for squareNumber in grid if squareNumber not in squaresGoRight]\n",
    "    return squaresGoRight, squaresGoUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_target(x):\n",
    "    ###Return the pmf corresponding to the target for square x (the behavior is picked depending on the square)\n",
    "\n",
    "    squaresGoRight, squaresGoUp = target_direction()\n",
    "\n",
    "    if x in squaresGoRight:  # For these squares, we want to go right\n",
    "        return ([0.01, 0.01, 0.01, 0.96, 0.01])  # Return the pmf corresponding to moving right\n",
    "\n",
    "    if x in squaresGoUp:  # For these squares, we want to go up\n",
    "        return ([0.01, 0.01, 0.96, 0.01, 0.01])  # Return the pmf corresponding to moving top\n",
    "\n",
    "    return ([0.96, 0.01, 0.01, 0.01, 0.01])  # Else, we want to stay on position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_obstacle_location():\n",
    "    # rand obstacle location\n",
    "    # get diffent amount of obstacle depended on grid size, for 3x3 1 obstacle, 4x4 2obstacle etc.\n",
    "\n",
    "    if (grid_dimension == 3):\n",
    "        number_of_obtacles = 1;\n",
    "    else:\n",
    "        number_of_obtacles = (grid_dimension - 2)\n",
    "\n",
    "    field_number_with_obtacle = []\n",
    "\n",
    "    for i in range(number_of_obtacles):\n",
    "        result = random.randrange(1, (fields_number - 1))  # without 1st and last square (for 5x5) w/o 0 and 24\n",
    "        field_number_with_obtacle.append(result)\n",
    "\n",
    "    print(f\"Fields with obstacles: {field_number_with_obtacle}\")\n",
    "    return field_number_with_obtacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_reward(x):\n",
    "\n",
    "    ###Return the reward function (voded as a list of its values) for square x\n",
    "    # Square zero (the starting point) has a reward of -1, and square 4 (the middle) has a reward of -100\n",
    "    # Again, this function picks the reward based on the square where the agent is\n",
    "    if (x + grid_dimension) in field_number_with_obtacle and not (x + 1) in field_number_with_obtacle:\n",
    "        return ([-1, -1, -100, 0, -1])  # obstacle ABOVE agent\n",
    "    if (x + 1) in field_number_with_obtacle and not (x + grid_dimension) in field_number_with_obtacle:\n",
    "        return ([-1, -1, 0, -100, -1])  # obstacle RIGHT side agent\n",
    "    if (x - 1) in field_number_with_obtacle:\n",
    "        return ([0, -100, 0, 0, 0])  # obstacle LEFT agent\n",
    "    if (x - grid_dimension) in field_number_with_obtacle:\n",
    "        return ([0, 0, 0, 0, -100])  # obstacle BELOW agent\n",
    "    if x in field_number_with_obtacle:\n",
    "        return ([-100, 0, 0, 0, 0])  # ARRR! agent in the obstacle\n",
    "    if (x + grid_dimension) in field_number_with_obtacle and (x + 1) in field_number_with_obtacle:\n",
    "        return [0, 0, -1000, -1000, 0]  # obstacle ABOVE and RIGHT side of agent\n",
    "    #if x == 0:\n",
    "      #  return ([-1, 0, 0, 0, 0])  # starting point\n",
    "    return ([0, 0, 0, 0, 0])  # else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sources(x):\n",
    "    ###Return the behavior of the sources for square x\n",
    "    source_left = [0.01, 0.96, 0.01, 0.01, 0.01]\n",
    "    source_top = [0.01, 0.01, 0.96, 0.01, 0.01]\n",
    "    source_right = [0.01, 0.01, 0.01, 0.96, 0.01]\n",
    "    source_bot = [0.01, 0.01, 0.01, 0.01, 0.96]\n",
    "    # source_stay = [0.96, 0.01, 0.01, 0.01, 0.01]\n",
    "\n",
    "    if findWall(x)[0]:  # If we are near a wall (or more), the corresponding movement is replaced by \"stay in place\"\n",
    "        source_left = [0.96, 0.01, 0.01, 0.01, 0.01]\n",
    "    if findWall(x)[1]:\n",
    "        source_top = [0.96, 0.01, 0.01, 0.01, 0.01]\n",
    "    if findWall(x)[2]:\n",
    "        source_right = [0.96, 0.01, 0.01, 0.01, 0.01]\n",
    "    if findWall(x)[3]:\n",
    "        source_bot = [0.96, 0.01, 0.01, 0.01, 0.01]\n",
    "\n",
    "    return (np.array([source_left, source_top, source_right, source_bot]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_state(position, action):\n",
    "    if action == 0:\n",
    "        return(position)\n",
    "    if action == 1:\n",
    "        return(position - 1)\n",
    "    if action == 2:\n",
    "        return(position + grid_dimension)\n",
    "    if action == 3:\n",
    "        return(position + 1)\n",
    "    if action == 4:\n",
    "        return(position - grid_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_algorithm(actual_position):\n",
    "    #     free_grids = findWall(actual_position) #check if there's no walls\n",
    "    #     available states = [i for i, x in enumerate(free_grids) if x == 0]\n",
    "    weights = np.zeros(S)\n",
    "\n",
    "    target = return_target(actual_position)\n",
    "    reward = return_reward(actual_position)\n",
    "    sources = return_sources(actual_position)\n",
    "\n",
    "    for i in range(S):\n",
    "        result_DKL = DKL(sources[i], target) - np.dot(sources[i], reward)  # Calculate the weight and store it\n",
    "        weights[i] = result_DKL\n",
    "\n",
    "    j = np.argmin(weights)  # Get the minimum weight\n",
    "    return (return_sources(actual_position)[j])  # Return the corresponding policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(actual_position):\n",
    "    ###\n",
    "    #Simulation loop\n",
    "    pmf = control_algorithm(actual_position)\n",
    "    action = np.argmax(pmf) #We use a maximum sampling\n",
    "    x = new_state(actual_position, action) #Get the corresponding new state\n",
    "    print('PMF: ' + str(pmf))\n",
    "    print('New state: ' + str(x))\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields with obstacles: [1, 6, 22]\n",
      "PMF: [0.01 0.01 0.96 0.01 0.01]\n",
      "New state: 5\n",
      "PMF: [0.01 0.01 0.96 0.01 0.01]\n",
      "New state: 10\n",
      "PMF: [0.01 0.01 0.01 0.96 0.01]\n",
      "New state: 11\n",
      "PMF: [0.01 0.01 0.01 0.96 0.01]\n",
      "New state: 12\n",
      "PMF: [0.01 0.01 0.01 0.96 0.01]\n",
      "New state: 13\n",
      "PMF: [0.01 0.01 0.96 0.01 0.01]\n",
      "New state: 18\n",
      "PMF: [0.01 0.01 0.01 0.96 0.01]\n",
      "New state: 19\n",
      "PMF: [0.01 0.01 0.96 0.01 0.01]\n",
      "New state: 24\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "x = 0\n",
    "state_memory.append(x)\n",
    "field_number_with_obtacle = rand_obstacle_location()\n",
    "# field_number_with_obtacle = [4]\n",
    "for i in range(fields_number-1):\n",
    "    if(x != fields_number-1):\n",
    "        x = loop(x)\n",
    "        state_memory.append(x)\n",
    "\n",
    "sim(grid_dimension, field_number_with_obtacle, state_memory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
